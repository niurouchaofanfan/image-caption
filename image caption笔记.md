# image caption笔记

### 基于模板的image caption方法

> 模板是预定义的且该方法只能生成固定长度的图像标题

### 基于检索的image caption方法（retrieval-based）

>在基于检索的方法中，字幕是从一组现有的字幕中检索出来的。基于检索的方法首先从训练数据集中找到具有标题的视觉相似的图像。这些标题称为候选标题。查询图像的标题是从这些标题池中选择的

>缺点是：只能生成语法正确的标题，不能生成语义正确的标题

### novel标题

> 这一类别的一般方法是首先分析图像的视觉内容，然后使用语言模型从视觉内容生成图像标题。

> 这类方法大多使用深度学习的方法，效果比先前的好

#### 图1描述了基于深度学习的图像字幕方法的总体分类。

<img src="1.png" alt="图1描述了基于深度学习的图像字幕方法的总体分类。" style="zoom:50%;" />

> 该图说明了不同类别的图像字幕方法的比较。基于图像字幕生成的图像字幕方法多采用视觉空间和基于深度机器学习的技术。字幕也可以从多模式空间生成。 基于深度学习的图像字幕方法也可以归类为以下学习技术：监督学习，强化学习和无监督学习。

### Visual Space vs. Multimodal Space

> 在基于视觉空间的方法中，图像特征和相应的字幕独立地传递给语言解码器。相比之下，在多模态空间中，共享多模态空间是从图像和相应的标题文本中学习的。然后将这个多模态表示传递给语言解码器。

#### 多模态空间

> 典型的多模态空间方法的体系结构包括语言编码器部分、视觉部分、多模态空间部分和语言解码器部分

> 视觉部分使用深度卷积神经网络作为特征提取器来提取图像特征。 语言编码器部分提取单词特征，并为每个单词学习密集的特征嵌入。 然后将语义时态上下文转发到递归层。多模态空间部分将图像特征映射到带有词特征的公共空间。然后，生成的映射被传递给语言解码器，后者通过解码映射生成标题。

>此类方法包括以下步骤：
>
>（1）使用深度神经网络和多模态神经语言模型在多模态空间中共同学习图像和文本。
>
>（2）语言生成部分使用步骤1中的信息生成字幕。

![基于空间的多模态图像字幕方法的总图如图2所示。](2.png)

​												基于空间的多模态图像字幕方法的总图如图2所示。

> Kiros et al. [69].的工作利用CNN提取图像特征，生成图像标题。它使用一个多模态空间来联合表示图像和文本，用于多模态表示学习和图像字幕生成。介绍了多模态神经语言模型。
>
> 与大多数以前的方法不同，此方法不依赖任何其他模板，结构或约束。 相反，它取决于分别从深度神经网络和多模式神经语言模型中学到的高级图像特征和单词表示。 神经语言模型有局限性，无法处理大量数据，并且无法有效地长期存储[64]。
>
> Kiros等。 [70]扩展了他们在[69]中的工作，学习了联合图像句子嵌入，其中LSTM用于句子编码，而新的神经语言模型称为**结构内容神经语言模型（****SC-NLM）用于图像字幕生成**。与现有方法相比，SC-NLM具有一个优点，即它**可以将句子的结构提取到编码器生成的内容中**。与[69]提出的方法相比，它还可以帮助他们在生成逼真的图像标题方面取得重大改进。

##### Mao等人[94]提出了一种多模态递归神经网络(m-RNN)方法

> 该方法有两个子网：用于语句的深度递归神经网络和用于图像的深度卷积网络。 这两个子网在多模式层中相互交互以形成整个m-RNN模型。 图像和句子片段都作为此方法的输入。 它计算概率分布以生成字幕的下一个单词。

> 此模型中还有五层：两个字嵌入层，循环层，多模态层和SoftMax层

> Kiros等。 [69]提出了一种基于对数-双线性模型的方法，并使用AlexNet提取视觉特征。 这种多模态递归神经网络方法与Kiros等人的方法密切相关。 [69]。 Kiros等。 使用固定长度的上下文（即五个词），而在此方法中，时间上下文存储在循环架构中，该架构允许任意上下文长度。

> 两个词嵌入层使用一个one-hot向量生成一个密集的词表示。它对这些词的句法意义和语义意义进行编码。通过计算嵌入层中两个密集词向量之间的欧氏距离，可以得到语义相关的词。

> 大多数句子-图像多模态方法[38,666,70,128]使用预先计算的词嵌入向量来初始化它们的模型。与此相反，**该方法随机初始化单词嵌入层，并从训练数据中学习它们。**这有助于他们产生更好的图像标题比以前的方法。**目前许多图像标注方法****[666,69,95]都是建立在递归神经网络上的。他们使用一个循环层来存储视觉信息。**但是，**（****m-RNN）同时使用图像表示和句子片段来生成标题。 它可以更有效地利用循环层的容量，从而有助于使用尺寸较小的循环层实现更好的性能。

### Supervised Learning vs. Other Deep Learning

> 在监督学习中，训练数据带有期望的输出，称为标签。 另一方面，无监督学习则处理未标记的数据。 生成对抗网络（GAN）[48]区域类型的无监督学习技术。 强化学习是另一种机器学习方法，其中代理的目的是通过探索和奖励信号发现数据和/或标签。 许多图像字幕方法使用强化学习和基于GAN的方法。

#### GAN方法

>基于GAN的方法可以从未标记的数据中学习深度特征。他们通过在两个网络(发生器和鉴别器)之间应用竞争过程来实现这种反馈。GAN已成功用于各种应用中，包括图像标注[26,126]，图像到图像翻译[56]，文本到图像合成[15,115]和文本生成[36，145]。

> GAN有两个问题。首先，GAN可以很好地从真实图像生成自然图像，因为它被用于实值数据。**然而，文本处理是基于离散数字的。因此，这些操作是不可微的，因此很难直接应用反向传播。**策略梯度应用一个参数函数来允许梯度反向传播。其次，评估者面临梯度消失和序列生成误差传播的问题。 每个局部描述都需要一个可能的未来奖励值。MonteCarlo展示[157]用于计算该未来奖励值。

> 与传统的深度卷积网络和基于深度递归网络模型相比，基于GAN的图像字幕方法可以生成多种图像字幕。Dai等人也提出了一种基于GAN的图像字幕方法。但是，他们不考虑单个图像的多个字幕。 Shetty等。 [126]引入了一种新的基于GAN的图像字幕方法。该方法可以为一幅图像生成多个标题，生成不同的字幕的改进效果显著。GANs在反向传播离散数据方面有局限性。Gumbel sampler[58,91]是用来克服离散数据问题的。这个对抗网络的两个主要部分是生成器和鉴别器。在训练中，生成器学习鉴别器提供的损失值，而不是从外部来源学习。鉴别器具有真实的数据分布，能够区分生成者生成的样本和真实的数据样本。这使得网络可以学习不同的数据分布。此外，该网络将生成的字幕集分为真字幕集和假字幕集。因此，它可以生成类似于人类生成的标题。